{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.resnet import resnet34\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import copy\n",
    "import pruning_funcs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and Load CIFAR-10 dataset\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data/train', train=True, download=True,transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data/test', train=False, download=True,transform=transform_test)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify ResNet34 Architecture for CIFAR-10\n",
    "class ModifiedResNet34(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModifiedResNet34, self).__init__()\n",
    "        self.model = resnet34(pretrained=True)\n",
    "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.model.maxpool = nn.Identity()\n",
    "        self.model.avgpool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)), nn.Dropout(0.5))  \n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GPU \n",
    "device = torch.device(\"mps\")\n",
    "model = ModifiedResNet34().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(testing_model, dataloader, suppress_output=False):\n",
    "    testing_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = testing_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    if not suppress_output:\n",
    "        print(f'Accuracy of the model on the test images: {accuracy}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function, optimizer, hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traning Loop\n",
    "def train_model(model, debug_interval = 200, save_model=True, use_saved_state=True):\n",
    "    for epoch in range(num_epochs):  \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % debug_interval == debug_interval-1:\n",
    "                print(f'Epoch {epoch + 1}, Batch {i + 1}: Loss: {running_loss / 200:.4f}')\n",
    "                print(f'\\tAcc (Test data): {evaluate_model(model, testloader, suppress_output=True)}')\n",
    "                running_loss = 0.0\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), \"resnet_state\")\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(model, debug_interval = 200, save_model=True)\n",
    "# Load the state dictionary from the file\n",
    "state_dict = torch.load(\"resnet_state\")\n",
    "new_state_dict = {f'model.{k}': v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "evaluate_model(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Pruning [Poor Results]\n",
    "%load_ext autoreload\n",
    "%autoreload now\n",
    "\n",
    "# percent_prune = []\n",
    "# percent_prune_with_bernoulli = []\n",
    "# percents = np.arange(1,10,1)\n",
    "\n",
    "# for percent in percents:\n",
    "#     pruned_model = copy.deepcopy(model)\n",
    "#     pruning_funcs.percent_prune_by_layer(pruned_model, device, percent=percent)\n",
    "#     percent_prune.append(evaluate_model(pruned_model, testloader, suppress_output=True))\n",
    "    \n",
    "#     ppwb_runs = []\n",
    "#     for i in range(5):\n",
    "#         pruned_model_2 = copy.deepcopy(model)\n",
    "#         pruning_funcs.percent_prune_with_bernoulli(pruned_model_2, device, percent=(2*percent), p_success=0.5)\n",
    "#         ppwb_runs.append(evaluate_model(pruned_model_2, testloader, suppress_output=True))\n",
    "\n",
    "#     percent_prune_with_bernoulli.append(np.mean(ppwb_runs))\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.set_title(\"Percent Pruning\")\n",
    "# line1, = ax.plot(percents, percent_prune, color='blue')\n",
    "# line2, = ax.plot(percents, percent_prune_with_bernoulli, color='orange')\n",
    "# line1.set_label(\"Percent Pruning\")\n",
    "# line2.set_label(\"Percent Pruning With Bernoulli (avg)\")\n",
    "# ax.legend()\n",
    "# ax.set_xlabel(\"Percent pruned (or expected pruned)\")\n",
    "# ax.set_ylabel(\"Model accuracy\")\n",
    "# ax.set_xticks(percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Laplace Distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def laplace_at(x, loc=0, scale=0.5):\n",
    "    return np.exp(-abs(x-loc)/scale)/(2.*scale)\n",
    "\n",
    "def graph_laplace_and_normalized(scale, loc=0, min=1):\n",
    "    x = np.arange(-2, 2, 0.01)\n",
    "    normalized_x = np.arange(-1, 1, 0.01)\n",
    "\n",
    "    laplace_dist = lambda y: laplace_at(y, scale=scale, loc=loc)\n",
    "    pdf = laplace_dist(x)\n",
    "    normalized_pdf = (laplace_dist(normalized_x) - laplace_dist(min)) / (laplace_dist(loc) - laplace_dist(min))\n",
    "    return ((x, pdf),(normalized_x, normalized_pdf))\n",
    "\n",
    "((x, pdf), (x2, modified_pdf)) = graph_laplace_and_normalized(0.5)\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(x, pdf)\n",
    "line1.set_label('Laplace')\n",
    "line2, = ax.plot(x2, modified_pdf)\n",
    "line2.set_label('Normalized Laplace')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Scale = 0.5')\n",
    "\n",
    "((x, pdf), (x2, modified_pdf)) = graph_laplace_and_normalized(1)\n",
    "((x3, pdf2), (x4, modified_pdf2)) = graph_laplace_and_normalized(0.25)\n",
    "\n",
    "fig2, (ax1, ax2) = plt.subplots(1,2, sharey=True)\n",
    "line1, = ax1.plot(x, pdf)\n",
    "line1.set_label('Laplace')\n",
    "line2, = ax1.plot(x2, modified_pdf)\n",
    "line2.set_label('Normalized Laplace')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Scale = 1')\n",
    "line3, = ax2.plot(x3, pdf2)\n",
    "line3.set_label('Laplace')\n",
    "line4, = ax2.plot(x4, modified_pdf2)\n",
    "line4.set_label('Normalized Laplace')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('Scale = 0.25')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload now\n",
    "\n",
    "tests = np.arange(0.002, 0.021, 0.002)\n",
    "num_trials = 5\n",
    "\n",
    "print()\n",
    "print('Avg. accuracy at scale values for Normalized Laplace Distribution')\n",
    "\n",
    "print()\n",
    "print('Unpruned Model')\n",
    "accuracy = evaluate_model(model, testloader, suppress_output=True)\n",
    "percent_zero = pruning_funcs.percent_zero_weights(model)\n",
    "print(f'Accuracy: {accuracy:.2f}%\\tPercent Zero: {percent_zero:.2f}%')\n",
    "\n",
    "print()\n",
    "print(\"Pruned Models (Normalized Laplace)\")\n",
    "for prune_scale in tests:\n",
    "    accuracy = 0.\n",
    "    percent_zeros = 0.\n",
    "    for i in range(num_trials):\n",
    "        pruned_model = copy.deepcopy(model)\n",
    "        pruning_funcs.normalized_laplace_prune(pruned_model, device, scale=prune_scale)\n",
    "        accuracy += evaluate_model(pruned_model, testloader, suppress_output=True)\n",
    "        percent_zeros += pruning_funcs.percent_zero_weights(pruned_model)\n",
    "    accuracy /= num_trials\n",
    "    percent_zeros /= num_trials\n",
    "    print(f'Scale: {prune_scale:.3f}\\tAvg. Accuracy: {accuracy:.2f}%\\tAvg. Percent Zero: {percent_zeros:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload now\n",
    "\n",
    "percents = np.arange(5,51,5)\n",
    "print()\n",
    "print(\"Pruned Models (Standard Percent Pruning By Layer)\")\n",
    "for percent in percents:\n",
    "    pruned_model = copy.deepcopy(model)\n",
    "    pruning_funcs.percent_prune_by_layer(pruned_model, device, percent=percent)\n",
    "    accuracy = evaluate_model(pruned_model, testloader, suppress_output=True)\n",
    "    percent_zero = pruning_funcs.percent_zero_weights(pruned_model)\n",
    "    print(f'Theoretic percent pruned: {percent}%\\tActual percent pruned: {percent_zero:.2f}%\\tAccuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload now\n",
    "\n",
    "percents = np.arange(5,51,5)\n",
    "print()\n",
    "print(\"Pruned Models (Standard Bottom Percent Pruning)\")\n",
    "for percent in percents:\n",
    "    pruned_model = copy.deepcopy(model)\n",
    "    pruning_funcs.bottom_percent_prune(pruned_model, device, percent=percent)\n",
    "    accuracy = evaluate_model(pruned_model, testloader, suppress_output=True)\n",
    "    percent_zero = pruning_funcs.percent_zero_weights(pruned_model)\n",
    "    print(f'Theoretic percent pruned: {percent}%\\tActual percent pruned: {percent_zero:.2f}%\\tAccuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload now\n",
    "\n",
    "thresholds = np.arange(0.002, 0.021, 0.002)\n",
    "\n",
    "print()\n",
    "print(\"Pruned Models (Standard Threshold Pruning)\")\n",
    "for threshold in thresholds:\n",
    "    pruned_model = copy.deepcopy(model)\n",
    "    pruning_funcs.threshold_prune(pruned_model, threshold)\n",
    "    accuracy = evaluate_model(pruned_model, testloader, suppress_output=True)\n",
    "    percent_zero = pruning_funcs.percent_zero_weights(pruned_model)\n",
    "    print(f'Threshold: {threshold:.3f}\\tPercent pruned: {percent_zero:.2f}%\\tAccuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
