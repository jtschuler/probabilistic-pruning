{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary packages and magic formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.resnet import resnet34\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import copy\n",
    "import pruning_funcs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and Load CIFAR-10 dataset\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data/train', train=True, download=True,transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data/test', train=False, download=True,transform=transform_test)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Modified ResNet Architecture for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify ResNet34 Architecture for CIFAR-10\n",
    "class ModifiedResNet34(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModifiedResNet34, self).__init__()\n",
    "        self.model = resnet34(pretrained=True)\n",
    "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.model.maxpool = nn.Identity()\n",
    "        self.model.avgpool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)), nn.Dropout(0.5))  \n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_features, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up MacBook GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GPU \n",
    "device = torch.device(\"mps\")\n",
    "model = ModifiedResNet34().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(testing_model, dataloader, suppress_output=False):\n",
    "    testing_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = testing_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    if not suppress_output:\n",
    "        print(f'Accuracy of the model on the test images: {accuracy}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function, optimizer, hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traning Loop\n",
    "def train_model(model, debug_interval = 200, save_model=True, use_saved_state=True):\n",
    "    for epoch in range(num_epochs):  \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % debug_interval == debug_interval-1:\n",
    "                print(f'Epoch {epoch + 1}, Batch {i + 1}: Loss: {running_loss / 200:.4f}')\n",
    "                print(f'\\tAcc (Test data): {evaluate_model(model, testloader, suppress_output=True)}')\n",
    "                running_loss = 0.0\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), \"resnet_state\")\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/ Load Weights\n",
    "This cell is where the model is trained (lines 1-2), or loaded from the state dict (lines 4-7). \n",
    "The intention is to either do one or the other, not both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(model, debug_interval = 200, save_model=True)\n",
    "# Load the state dictionary from the file\n",
    "state_dict = torch.load(\"resnet_state\")\n",
    "new_state_dict = {f'model.{k}': v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "evaluate_model(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Percent Pruning (Algorithm 2 in Paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Pruning\n",
    "%autoreload now\n",
    "\n",
    "percent_prune = []\n",
    "percent_prune_with_bernoulli = []\n",
    "percents = np.arange(1,10,1)\n",
    "\n",
    "for percent in percents:\n",
    "    pruned_model = copy.deepcopy(model)\n",
    "    pruning_funcs.bottom_percent_prune(pruned_model, device, percent=percent)\n",
    "    percent_prune.append(evaluate_model(pruned_model, testloader, suppress_output=True))\n",
    "    \n",
    "    ppwb_runs = []\n",
    "    for i in range(30):\n",
    "        pruned_model_2 = copy.deepcopy(model)\n",
    "        pruning_funcs.percent_prune_with_bernoulli(pruned_model_2, device, percent=(2*percent), p_success=0.5)\n",
    "        ppwb_runs.append(evaluate_model(pruned_model_2, testloader, suppress_output=True))\n",
    "\n",
    "    percent_prune_with_bernoulli.append(np.mean(ppwb_runs))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Percent Pruning\")\n",
    "line1, = ax.plot(percents, percent_prune, color='blue')\n",
    "line2, = ax.plot(percents, percent_prune_with_bernoulli, color='orange')\n",
    "line1.set_label(\"Percent Pruning\")\n",
    "line2.set_label(\"Percent Pruning With Bernoulli (avg)\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Percent pruned (or expected pruned)\")\n",
    "ax.set_ylabel(\"Model accuracy\")\n",
    "ax.set_xticks(percents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Normalized Laplace distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Laplace Distribution\n",
    "\n",
    "def laplace_at(x, loc=0, scale=0.5):\n",
    "    return np.exp(-abs(x-loc)/scale)/(2.*scale)\n",
    "\n",
    "def graph_laplace_and_normalized(scale, loc=0, min=1):\n",
    "    x = np.arange(-2, 2, 0.01)\n",
    "    normalized_x = np.arange(-1, 1, 0.01)\n",
    "\n",
    "    laplace_dist = lambda y: laplace_at(y, scale=scale, loc=loc)\n",
    "    pdf = laplace_dist(x)\n",
    "    normalized_pdf = (laplace_dist(normalized_x) - laplace_dist(min)) / (laplace_dist(loc) - laplace_dist(min))\n",
    "    return ((x, pdf),(normalized_x, normalized_pdf))\n",
    "\n",
    "((x, pdf), (x2, modified_pdf)) = graph_laplace_and_normalized(0.5)\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(x, pdf)\n",
    "line1.set_label('Laplace')\n",
    "line2, = ax.plot(x2, modified_pdf)\n",
    "line2.set_label('Normalized Laplace')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Scale = 0.5')\n",
    "\n",
    "((x, pdf), (x2, modified_pdf)) = graph_laplace_and_normalized(1)\n",
    "((x3, pdf2), (x4, modified_pdf2)) = graph_laplace_and_normalized(0.25)\n",
    "\n",
    "fig2, (ax1, ax2) = plt.subplots(1,2, sharey=True)\n",
    "line1, = ax1.plot(x, pdf)\n",
    "line1.set_label('Laplace')\n",
    "line2, = ax1.plot(x2, modified_pdf)\n",
    "line2.set_label('Normalized Laplace')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Scale = 1')\n",
    "line3, = ax2.plot(x3, pdf2)\n",
    "line3.set_label('Laplace')\n",
    "line4, = ax2.plot(x4, modified_pdf2)\n",
    "line4.set_label('Normalized Laplace')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('Scale = 0.25')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Laplace Pruning (Algorithm 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg. accuracy at scale values for Normalized Laplace Distribution\n",
      "\n",
      "Unpruned Model\n",
      "Accuracy: 95.46%\tPercent Zero: 0.00%\n",
      "\n",
      "Pruned Models (Normalized Laplace)\n",
      "Scale: 0.002\tAvg. Accuracy: 95.39%\tAvg. Percent Zero: 11.90%\n",
      "Scale: 0.004\tAvg. Accuracy: 95.37%\tAvg. Percent Zero: 22.31%\n",
      "Scale: 0.006\tAvg. Accuracy: 95.02%\tAvg. Percent Zero: 30.94%\n",
      "Scale: 0.008\tAvg. Accuracy: 94.58%\tAvg. Percent Zero: 38.03%\n",
      "Scale: 0.010\tAvg. Accuracy: 93.95%\tAvg. Percent Zero: 43.87%\n",
      "Scale: 0.012\tAvg. Accuracy: 93.12%\tAvg. Percent Zero: 48.75%\n",
      "Scale: 0.014\tAvg. Accuracy: 91.58%\tAvg. Percent Zero: 52.87%\n",
      "Scale: 0.016\tAvg. Accuracy: 89.95%\tAvg. Percent Zero: 56.38%\n",
      "Scale: 0.018\tAvg. Accuracy: 86.80%\tAvg. Percent Zero: 59.42%\n",
      "Scale: 0.020\tAvg. Accuracy: 81.18%\tAvg. Percent Zero: 62.06%\n"
     ]
    }
   ],
   "source": [
    "# Normalized Laplace\n",
    "\n",
    "%autoreload now\n",
    "\n",
    "tests = np.arange(0.002, 0.021, 0.002)\n",
    "num_trials = 30\n",
    "\n",
    "print()\n",
    "print('Avg. accuracy at scale values for Normalized Laplace Distribution')\n",
    "\n",
    "print()\n",
    "print('Unpruned Model')\n",
    "accuracy = evaluate_model(model, testloader, suppress_output=True)\n",
    "percent_zero = pruning_funcs.percent_zero_weights(model)\n",
    "print(f'Accuracy: {accuracy:.2f}%\\tPercent Zero: {percent_zero:.2f}%')\n",
    "\n",
    "print()\n",
    "print(\"Pruned Models (Normalized Laplace)\")\n",
    "for prune_scale in tests:\n",
    "    accuracy = 0.\n",
    "    percent_zeros = 0.\n",
    "    for i in range(num_trials):\n",
    "        pruned_model = copy.deepcopy(model)\n",
    "        pruning_funcs.normalized_laplace_prune(pruned_model, device, scale=prune_scale)\n",
    "        accuracy += evaluate_model(pruned_model, testloader, suppress_output=True)\n",
    "        percent_zeros += pruning_funcs.percent_zero_weights(pruned_model)\n",
    "    accuracy /= num_trials\n",
    "    percent_zeros /= num_trials\n",
    "    print(f'Scale: {prune_scale:.3f}\\tAvg. Accuracy: {accuracy:.2f}%\\tAvg. Percent Zero: {percent_zeros:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Percent by Layer Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruned Models (Standard Percent Pruning By Layer)\n",
      "Theoretic percent pruned: 5%\tActual percent pruned: 5.00%\tAccuracy: 93.98%\n",
      "Theoretic percent pruned: 10%\tActual percent pruned: 10.00%\tAccuracy: 91.11%\n",
      "Theoretic percent pruned: 15%\tActual percent pruned: 15.00%\tAccuracy: 84.52%\n",
      "Theoretic percent pruned: 20%\tActual percent pruned: 20.00%\tAccuracy: 73.08%\n",
      "Theoretic percent pruned: 25%\tActual percent pruned: 25.00%\tAccuracy: 47.19%\n",
      "Theoretic percent pruned: 30%\tActual percent pruned: 30.00%\tAccuracy: 20.78%\n",
      "Theoretic percent pruned: 35%\tActual percent pruned: 35.00%\tAccuracy: 13.08%\n",
      "Theoretic percent pruned: 40%\tActual percent pruned: 40.00%\tAccuracy: 10.03%\n",
      "Theoretic percent pruned: 45%\tActual percent pruned: 45.00%\tAccuracy: 10.10%\n",
      "Theoretic percent pruned: 50%\tActual percent pruned: 50.00%\tAccuracy: 9.97%\n"
     ]
    }
   ],
   "source": [
    "# Percent by Layer\n",
    "\n",
    "%autoreload now\n",
    "\n",
    "percents = np.arange(5,51,5)\n",
    "print()\n",
    "print(\"Pruned Models (Standard Percent Pruning By Layer)\")\n",
    "for percent in percents:\n",
    "    pruned_model = copy.deepcopy(model)\n",
    "    pruning_funcs.percent_prune_by_layer(pruned_model, device, percent=percent)\n",
    "    accuracy = evaluate_model(pruned_model, testloader, suppress_output=True)\n",
    "    percent_zero = pruning_funcs.percent_zero_weights(pruned_model)\n",
    "    print(f'Theoretic percent pruned: {percent}%\\tActual percent pruned: {percent_zero:.2f}%\\tAccuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Prune Algorithm 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruned Models (Standard Bottom Percent Pruning)\n",
      "Theoretic percent pruned: 5%\tActual percent pruned: 5.00%\tAccuracy: 95.45%\n",
      "Theoretic percent pruned: 10%\tActual percent pruned: 10.00%\tAccuracy: 95.50%\n",
      "Theoretic percent pruned: 15%\tActual percent pruned: 15.00%\tAccuracy: 95.34%\n",
      "Theoretic percent pruned: 20%\tActual percent pruned: 20.00%\tAccuracy: 95.36%\n",
      "Theoretic percent pruned: 25%\tActual percent pruned: 25.00%\tAccuracy: 95.34%\n",
      "Theoretic percent pruned: 30%\tActual percent pruned: 30.00%\tAccuracy: 95.28%\n",
      "Theoretic percent pruned: 35%\tActual percent pruned: 35.00%\tAccuracy: 95.38%\n",
      "Theoretic percent pruned: 40%\tActual percent pruned: 40.00%\tAccuracy: 95.25%\n",
      "Theoretic percent pruned: 45%\tActual percent pruned: 45.00%\tAccuracy: 95.16%\n",
      "Theoretic percent pruned: 50%\tActual percent pruned: 50.00%\tAccuracy: 94.91%\n"
     ]
    }
   ],
   "source": [
    "# Bottom Percent\n",
    "\n",
    "%autoreload now\n",
    "percents = np.arange(5,51,5)\n",
    "print()\n",
    "print(\"Pruned Models (Standard Bottom Percent Pruning)\")\n",
    "for percent in percents:\n",
    "    pruned_model = copy.deepcopy(model)\n",
    "    pruning_funcs.bottom_percent_prune(pruned_model, device, percent=percent)\n",
    "    accuracy = evaluate_model(pruned_model, testloader, suppress_output=True)\n",
    "    percent_zero = pruning_funcs.percent_zero_weights(pruned_model)\n",
    "    print(f'Theoretic percent pruned: {percent}%\\tActual percent pruned: {percent_zero:.2f}%\\tAccuracy: {accuracy:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
