{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages (and magic formulas), define model, and download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.resnet import resnet34\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import copy\n",
    "import pruning_funcs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# Load CIFAR-10\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained EfficientNet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained EfficientNet\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=10)\n",
    "device = torch.device(\"mps\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hyperparameters for further training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train or Load Weights\n",
    "This cell is where we either train the model (lines 1-11), or load our previously trained model (lines 13-14). The intention is to either do one or the other, not both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training loop\n",
    "# for epoch in range(10):  # number of epochs\n",
    "#     model.train()\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "state_dict = torch.load(\"efficientnet_state\")\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define method for evaluating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(testing_model, dataloader, suppress_output=False):\n",
    "    testing_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = testing_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    if not suppress_output:\n",
    "        print(f'Accuracy of the model on the test images: {accuracy}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning methods begin here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test normalized Laplace pruning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg. accuracy at scale values for Normalized Laplace Distribution\n",
      "\n",
      "Unpruned Model\n",
      "Accuracy: 93.01%\tPercent Zero: 0.00%\n",
      "\n",
      "Pruned Models (Normalized Laplace)\n",
      "Scale: 0.008\tAvg. Accuracy: 92.97%\tAvg. Percent Zero: 5.42%\n",
      "Scale: 0.016\tAvg. Accuracy: 92.90%\tAvg. Percent Zero: 10.67%\n",
      "Scale: 0.024\tAvg. Accuracy: 92.23%\tAvg. Percent Zero: 15.61%\n",
      "Scale: 0.032\tAvg. Accuracy: 91.38%\tAvg. Percent Zero: 20.24%\n",
      "Scale: 0.040\tAvg. Accuracy: 89.68%\tAvg. Percent Zero: 24.51%\n",
      "Scale: 0.048\tAvg. Accuracy: 81.53%\tAvg. Percent Zero: 28.43%\n",
      "Scale: 0.056\tAvg. Accuracy: 63.17%\tAvg. Percent Zero: 32.01%\n",
      "Scale: 0.064\tAvg. Accuracy: 50.05%\tAvg. Percent Zero: 35.31%\n",
      "Scale: 0.072\tAvg. Accuracy: 24.65%\tAvg. Percent Zero: 38.35%\n",
      "Scale: 0.080\tAvg. Accuracy: 11.62%\tAvg. Percent Zero: 41.12%\n"
     ]
    }
   ],
   "source": [
    "# Normalized Laplace\n",
    "\n",
    "%autoreload now\n",
    "\n",
    "tests = np.arange(0.008, 0.081, 0.008)\n",
    "num_trials = 5\n",
    "\n",
    "print()\n",
    "print('Avg. accuracy at scale values for Normalized Laplace Distribution')\n",
    "\n",
    "print()\n",
    "print('Unpruned Model')\n",
    "\n",
    "accuracy = evaluate_model(model, test_loader, suppress_output=True)\n",
    "percent_zero = pruning_funcs.percent_zero_weights(model)\n",
    "print(f'Accuracy: {accuracy:.2f}%\\tPercent Zero: {percent_zero:.2f}%')\n",
    "\n",
    "print()\n",
    "print(\"Pruned Models (Normalized Laplace)\")\n",
    "for prune_scale in tests:\n",
    "    accuracy = 0.\n",
    "    percent_zeros = 0.\n",
    "    for i in range(num_trials):\n",
    "        pruned_model = copy.deepcopy(model)\n",
    "        pruning_funcs.normalized_laplace_prune(pruned_model, device, scale=prune_scale)\n",
    "        accuracy += evaluate_model(pruned_model, test_loader, suppress_output=True)\n",
    "        percent_zeros += pruning_funcs.percent_zero_weights(pruned_model)\n",
    "    accuracy /= num_trials\n",
    "    percent_zeros /= num_trials\n",
    "    print(f'Scale: {prune_scale:.3f}\\tAvg. Accuracy: {accuracy:.2f}%\\tAvg. Percent Zero: {percent_zeros:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test percent by layer pruning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruned Models (Standard Percent Pruning By Layer)\n",
      "Theoretic percent pruned: 5%\tActual percent pruned: 5.00%\tAccuracy: 82.65%\n",
      "Theoretic percent pruned: 10%\tActual percent pruned: 10.00%\tAccuracy: 26.52%\n",
      "Theoretic percent pruned: 15%\tActual percent pruned: 15.00%\tAccuracy: 10.16%\n",
      "Theoretic percent pruned: 20%\tActual percent pruned: 20.00%\tAccuracy: 10.00%\n",
      "Theoretic percent pruned: 25%\tActual percent pruned: 25.00%\tAccuracy: 10.00%\n",
      "Theoretic percent pruned: 30%\tActual percent pruned: 30.00%\tAccuracy: 10.00%\n",
      "Theoretic percent pruned: 35%\tActual percent pruned: 35.00%\tAccuracy: 10.00%\n",
      "Theoretic percent pruned: 40%\tActual percent pruned: 40.00%\tAccuracy: 10.00%\n",
      "Theoretic percent pruned: 45%\tActual percent pruned: 45.00%\tAccuracy: 10.00%\n",
      "Theoretic percent pruned: 50%\tActual percent pruned: 50.00%\tAccuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "# Percent by Layer\n",
    "\n",
    "%autoreload now\n",
    "\n",
    "percents = np.arange(5,51,5)\n",
    "print()\n",
    "print(\"Pruned Models (Standard Percent Pruning By Layer)\")\n",
    "for percent in percents:\n",
    "    pruned_model = copy.deepcopy(model)\n",
    "    pruning_funcs.percent_prune_by_layer(pruned_model, device, percent=percent)\n",
    "    accuracy = evaluate_model(pruned_model, test_loader, suppress_output=True)\n",
    "    percent_zero = pruning_funcs.percent_zero_weights(pruned_model)\n",
    "    print(f'Theoretic percent pruned: {percent}%\\tActual percent pruned: {percent_zero:.2f}%\\tAccuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test bottom percent pruning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruned Models (Standard Bottom Percent Pruning)\n",
      "Theoretic percent pruned: 5%\tActual percent pruned: 5.00%\tAccuracy: 92.98%\n",
      "Theoretic percent pruned: 10%\tActual percent pruned: 10.00%\tAccuracy: 92.89%\n",
      "Theoretic percent pruned: 15%\tActual percent pruned: 15.00%\tAccuracy: 92.89%\n",
      "Theoretic percent pruned: 20%\tActual percent pruned: 20.00%\tAccuracy: 92.80%\n",
      "Theoretic percent pruned: 25%\tActual percent pruned: 25.00%\tAccuracy: 92.80%\n",
      "Theoretic percent pruned: 30%\tActual percent pruned: 30.00%\tAccuracy: 92.22%\n",
      "Theoretic percent pruned: 35%\tActual percent pruned: 35.00%\tAccuracy: 92.04%\n",
      "Theoretic percent pruned: 40%\tActual percent pruned: 40.00%\tAccuracy: 90.31%\n",
      "Theoretic percent pruned: 45%\tActual percent pruned: 45.00%\tAccuracy: 88.48%\n",
      "Theoretic percent pruned: 50%\tActual percent pruned: 50.00%\tAccuracy: 79.47%\n"
     ]
    }
   ],
   "source": [
    "# Bottom Percent\n",
    "\n",
    "%autoreload now\n",
    "\n",
    "percents = np.arange(5,51,5)\n",
    "print()\n",
    "print(\"Pruned Models (Standard Bottom Percent Pruning)\")\n",
    "for percent in percents:\n",
    "    pruned_model = copy.deepcopy(model)\n",
    "    pruning_funcs.bottom_percent_prune(pruned_model, device, percent=percent)\n",
    "    accuracy = evaluate_model(pruned_model, test_loader, suppress_output=True)\n",
    "    percent_zero = pruning_funcs.percent_zero_weights(pruned_model)\n",
    "    print(f'Theoretic percent pruned: {percent}%\\tActual percent pruned: {percent_zero:.2f}%\\tAccuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test standard threshold (magnitude) based pruning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruned Models (Standard Threshold Pruning)\n",
      "Threshold: 0.008\tPercent pruned: 5.44%\tAccuracy: 92.94%\n",
      "Threshold: 0.016\tPercent pruned: 10.86%\tAccuracy: 93.01%\n",
      "Threshold: 0.024\tPercent pruned: 16.23%\tAccuracy: 92.73%\n",
      "Threshold: 0.032\tPercent pruned: 21.48%\tAccuracy: 92.89%\n",
      "Threshold: 0.040\tPercent pruned: 26.59%\tAccuracy: 92.53%\n",
      "Threshold: 0.048\tPercent pruned: 31.57%\tAccuracy: 92.36%\n",
      "Threshold: 0.056\tPercent pruned: 36.39%\tAccuracy: 91.68%\n",
      "Threshold: 0.064\tPercent pruned: 41.04%\tAccuracy: 89.42%\n",
      "Threshold: 0.072\tPercent pruned: 45.48%\tAccuracy: 88.34%\n",
      "Threshold: 0.080\tPercent pruned: 49.74%\tAccuracy: 80.94%\n"
     ]
    }
   ],
   "source": [
    "# Threshold\n",
    "\n",
    "%autoreload now\n",
    "\n",
    "thresholds = np.arange(0.008, 0.081, 0.008)\n",
    "\n",
    "print()\n",
    "print(\"Pruned Models (Standard Threshold Pruning)\")\n",
    "for threshold in thresholds:\n",
    "    pruned_model = copy.deepcopy(model)\n",
    "    pruning_funcs.threshold_prune(pruned_model, threshold)\n",
    "    accuracy = evaluate_model(pruned_model, test_loader, suppress_output=True)\n",
    "    percent_zero = pruning_funcs.percent_zero_weights(pruned_model)\n",
    "    print(f'Threshold: {threshold:.3f}\\tPercent pruned: {percent_zero:.2f}%\\tAccuracy: {accuracy:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
